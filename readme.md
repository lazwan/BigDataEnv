# å¤§æ•°æ®ç¯å¢ƒæ­å»ºéƒ¨åˆ†

### æ³¨æ„ï¼š

- ç¯å¢ƒæ­å»ºæ‰€éœ€è¦çš„å®‰è£…åŒ…éœ€è¦æå‰ä½¿ç”¨ `xftp`ä¸Šä¼ ï¼Œæœ¬æ–‡æ¡£é»˜è®¤æ”¾åœ¨è™šæ‹Ÿæœºçš„`/root`ç›®å½•ä¸‹
- ç¯å¢ƒæ­å»ºæ‰€éœ€å®‰è£…åŒ… [ä¸‹è½½é“¾æ¥](https://pan.baidu.com/s/1vk1wVTdVxyY5wuD9Q1XUvg), æå–ç ï¼š`data`
- è¯·å­¦ä¼šä½¿ç”¨  `Tab` é”®è¿›è¡Œè¡¥å…¨æ–‡ä»¶è·¯å¾„

#### 1ã€è™šæ‹Ÿæœºå®‰è£…

è¿™é‡Œæˆ‘ä»¬é»˜è®¤ä½¿ç”¨çš„æ˜¯ `VMware 16` ï¼Œ`VMware 15`ä¹Ÿå¯ä»¥ï¼Œ`CentosOS`ç‰ˆæœ¬é€‰æ‹©çš„æ˜¯ `CentOS 7`

å…·ä½“å®‰è£…è¯·çœ‹ğŸ‘‰ [è™šæ‹Ÿæœºå®‰è£…CentOS 7](https://gitee.com/lazywa/BigData/blob/master/è™šæ‹Ÿæœºå®‰è£…CentOS7.md)

#### 2ã€å…‹éš†è™šæ‹Ÿæœºã€è¿æ¥ `Xshell`

è¿™é‡Œæˆ‘ä»¬çº¦å®šä¸‰å°è™šæ‹Ÿæœºåç§°é»˜è®¤ä¸º `master`ã€`slave1`ã€`slave2` (æ¯”èµ›ä¸­ä¼šæœ‰ä¸åŒçš„è¦æ±‚)

å…·ä½“å®‰è£…è¯·çœ‹ğŸ‘‰[è™šæ‹Ÿæœºå…‹éš†ã€è¿æ¥Xshell](https://gitee.com/lazywa/BigData/blob/master/è™šæ‹Ÿæœºå…‹éš†ã€è¿æ¥Xshell.md)

#### 3ã€å…³é—­é˜²ç«å¢™(ä¸‰å°è™šæ‹Ÿæœºéƒ½è¦æ“ä½œ)

è¯·æ ¹åŸºä½ çš„ç³»ç»Ÿç‰ˆæœ¬é€‰æ‹©å¯¹åº”çš„å‘½ä»¤

- Centos 7 å‘½ä»¤ (ä¸¤æ¡å‘½ä»¤åˆ†åˆ«æ‰§è¡Œ)

  ```shell
  systemctl stop firewalld.service
  systemctl disable firewalld.service
  ```

- Centos 6 å‘½ä»¤ (ä¸¤æ¡å‘½ä»¤åˆ†åˆ«æ‰§è¡Œ)

  ```shell
  service iptables stop
  chkconfig iptables off
  ```

#### 4ã€ä¿®æ”¹ hostsï¼Œæ”¹å®Œæ‹·è´åˆ°å¦å¤–ä¸¤å°æœºå™¨

å‘½ä»¤ï¼š

```shell
vim /etc/hosts
```

æ·»åŠ ä»¥ä¸‹å†…å®¹:

**è¯·æ³¨æ„æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š**

- ä¸»æœºåä¸­**ä¸€å®šä¸€å®šä¸€å®š**ä¸èƒ½æœ‰ä¸‹åˆ’çº¿ã€è¿æ¥ç¬¦ï¼ï¼ï¼
- è¯·ä¸è¦å¤åˆ¶ä»¥ä¸‹å†…å®¹ç›´æ¥ç”¨ï¼Œéœ€è¦å°†`master_ip`æ”¹æˆå¯¹åº”ä¸»æœºçš„ IP åœ°å€(å…·ä½“è¯·çœ‹æœ€åçš„ç¤ºä¾‹)

- æ¯”èµ›æ—¶æ ¹æ®å®˜æ–¹è¦æ±‚ç»Ÿä¸€ä½¿ç”¨ `azy01slave1`, `azy01sla` ç±»çš„åå­—

```shell
master_ip	master
slave1_ip	slave1
slave2_ip	slave2
```

ç¤ºä¾‹ï¼š

![image-20201125235322838](image/image-20201125235322838.png)

æ‹·è´ `hosts` åˆ°å¦å¤–ä¸¤å°è™šæ‹Ÿæœº

å‘½ä»¤(è¯·**é€æ¡åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œ**)ï¼š

```shell
scp /etc/hosts slave1:/etc/hosts
scp /etc/hosts slave2:/etc/hosts
```

#### 5ã€é…ç½®å…å¯†ç™»å½•ï¼ˆåœ¨ master ä¸Šï¼‰

ç”Ÿæˆ SSH å…¬é’¥(éœ€è¦**æŒ‰å¤šæ¬¡å›è½¦**ï¼Œç›´åˆ°å‡ºç°ä¸€ä¸ªâ€œæ¡†â€)

```shell
ssh-keygen -t rsa
```

é…ç½®ä¸‰å°ä¸»æœºçš„å…å¯†ç™»å½•(è¯·**é€æ¡åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œ**ï¼Œåé¢çš„ä¸»æœºåç§°æ ¹æ®å¤§å®¶åœ¨ `hosts` é‡Œçš„é…ç½®å¡«å†™)

```shell
ssh-copy-id -i master
ssh-copy-id -i slave2
ssh-copy-id -i slave1
```

#### 6ã€å®‰è£… JDK

1. è§£å‹ `jdk` å®‰è£…åŒ…

   ```shell
   tar -zxvf jdk-8u192-linux-x64.tar.gz
   ```

2. å°†è§£å‹å‡ºæ¥çš„æ–‡ä»¶å¤¹ `jdk1.8.0_192` ç§»åŠ¨åˆ° `/opt` ç›®å½•ä¸‹ï¼Œå¹¶ä¿®æ”¹æ–‡ä»¶å¤¹åç§°ä¸º `jdk`

   å¯ä»¥å…ˆä½¿ç”¨ `ls` å‘½ä»¤æŸ¥çœ‹è§£å‹å‡ºæ¥çš„æ–‡ä»¶å¤¹åç§°ï¼Œå¯èƒ½ä¸æ–‡æ¡£æœ‰å·®å¼‚ï¼Œè¯·æŒ‰è‡ªå·±è§£å‹å‡ºæ¥çš„**æ–‡ä»¶å¤¹åç§°**æ“ä½œ

   ```shell
   mv jdk1.8.0_192 /opt/jdk
   ```

3. é…ç½® `jdk` ç¯å¢ƒå˜é‡

   å‘½ä»¤ï¼š

   ```shell
   vim /etc/profile
   ```

   åœ¨æ³¨é‡Šçš„æœ€åä¸€è¡Œæ·»åŠ ä»¥ä¸‹å†…å®¹ (å¦‚ä¸‹å›¾)

   ```shell
   export JAVA_HOME=/opt/jdk
   export PATH=$JAVA_HOME/bin:$PATH
   ```

   ![image-20201125235224054](image/image-20201125235224054.png)

4. æ˜¾ç¤ºå½“å‰ç¯å¢ƒå˜é‡(å¯é€‰ï¼Œä½œç”¨ä¸ºå¤‡ä»½ PATHï¼Œé˜²æ­¢ PATH å˜é‡å—æŸï¼Œæ— æ³•æ¢å¤)

   ```shell
   echo $PATH
   ```

   æ­¤æ—¶ä¼šè¾“å‡ºä¸€ä¸ªç±»ä¼¼ä»¥ä¸‹çš„å†…å®¹

   ```shell
   /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
   ```

   å¦‚æœç¯å¢ƒå˜é‡é…ç½®é”™äº†ï¼Œå¯ä»¥é€šè¿‡è¿™ä¸ªè¿›è¡Œæ¢å¤

   æ¢å¤å‘½ä»¤ï¼š

   ```shell
   export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
   ```

5. ä½¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ

   å‘½ä»¤ï¼š

   ```shell
   source /etc/profile
   ```

   è‹¥ `source`å `ls`ã€`cd`ç­‰æŒ‡ä»¤æ²¡æœ‰äº†ï¼Œå¯ä»¥é€šè¿‡ä¸Šä¸€æ­¥è¿›è¡Œæ¢å¤ï¼Œç„¶åé‡æ–°ä¿®æ”¹ `profile`æ–‡ä»¶

6. å¤åˆ¶ç¯å¢ƒå˜é‡åˆ°å¦å¤–ä¸¤å°æœºå™¨ä¸Š((è¯·**é€æ¡åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œ**)

   ```shell
   scp /etc/profile slave1:/etc
   scp /etc/profile slave2:/etc
   ```

7. å¤åˆ¶ `jdk` åˆ°å¦å¤–ä¸¤å°æœºå™¨ä¸Š((è¯·**é€æ¡åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œ**)

   ```shell
   scp -r /opt/jdk slave1:/opt
   scp -r /opt/jdk slave2:/opt
   ```

#### 7ã€`hadoop` é…ç½®

1. è§£å‹ `hadoop` å®‰è£…åŒ…

   ```shell
   tar -zxvf hadoop-2.7.6.tar.gz
   ```

2. å°†è§£å‹å‡ºæ¥çš„æ–‡ä»¶å¤¹ ` hadoop-2.7.6.` ç§»åŠ¨åˆ° `/opt` ç›®å½•ä¸‹ï¼Œå¹¶ä¿®æ”¹æ–‡ä»¶å¤¹åç§°ä¸º `hadoop`

   ```shell
   mv hadoop-2.7.6 /opt/hadoop
   ```

3. é…ç½®`hadoop`ç¯å¢ƒå˜é‡

   å‘½ä»¤ï¼š`vim /etc/profile` (åœ¨åˆšåˆšé…ç½®çš„ `jdk` ç¯å¢ƒå˜é‡åæ·»åŠ å³å¯)

   ```shell
   export HADOOP_HOME=/opt/hadoop
   export PATH=$HADOOP_HOME/bin:$PATH
   ```
   ä½¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ

   ```shell
   source /etc/profile
   ```

4. å¤åˆ¶ç¯å¢ƒå˜é‡åˆ°å¦å¤–ä¸¤å°æœºå™¨ä¸Š((è¯·**é€æ¡åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œ**)

   ```shell
   scp /etc/profile slave1:/etc
   scp /etc/profile slave2:/etc
   ```
   
5. ä¿®æ”¹ `hadoop` çš„é…ç½®æ–‡ä»¶

   1. è¿›å…¥ `hadoop` é…ç½®æ–‡ä»¶çš„æ–‡ä»¶å¤¹

      ```shell
      cd /opt/hadoop/etc/hadoop
      ```

   2. ä¿®æ”¹ `slaves `

      å‘½ä»¤ï¼š

      ```shell
      vim slaves
      ```

      å…ˆåˆ é™¤é‡Œé¢çš„ `localhost`ï¼Œç„¶åæ·»åŠ ä»¥ä¸‹å†…å®¹

      ```
      slave1
      slave2
      ```

   3. ä¿®æ”¹ `hadoop-env.sh`

      å‘½ä»¤ï¼š

      ```shell
      vim hadoop-env.sh
      ```

      å°† `JAVA_HOME` ä¿®æ”¹æˆ

      ```shell
      export JAVA_HOME=/opt/jdk
      ```

      ![image-20201126000041086](image/image-20201126000041086.png)

   4. ä¿®æ”¹ `core-site.xml`

      å‘½ä»¤ï¼š

      ```shell
      vim core-site.xml
      ```

      æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š(ä¸€å®šè¦åœ¨ `<configuration> </configuration>` ä¹‹é—´æ·»åŠ )

      ```xml
      <property>
          <name>fs.defaultFS</name>
          <value>hdfs://master:9000</value>
      </property>
      
      <property>
          <name>hadoop.tmp.dir</name>
          <value>/opt/hadoop/tmp</value>
      </property>
      ```

      ![image-20201126000325569](image/image-20201126000325569.png)

   5. ä¿®æ”¹ `hdfs-site.xml`

      å‘½ä»¤ï¼š

      ```shell
      vim hdfs-site.xml
      ```

      æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š(ä¸€å®šè¦åœ¨ `<configuration> </configuration>` ä¹‹é—´æ·»åŠ )

      ```xml
      <property>
          <name>dfs.replication</name>
          <value>1</value>
      </property>
      ```

   6. ä¿®æ”¹ `mapred-site.xml`

      - ä» `mapred-site.xml.template`å¤åˆ¶å‡º `mapred-site.xml`

        å‘½ä»¤ï¼š
      
        ```shell
        cp mapred-site.xml.template mapred-site.xml
        ```

       - ç”¨ `vim ` ç¼–è¾‘

         å‘½ä»¤ï¼š

         ```
         vim mapred-site.xml
         ```

         æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š(ä¸€å®šè¦åœ¨ `<configuration> </configuration>` ä¹‹é—´æ·»åŠ )

         ```xml
         <property>
             <name>mapreduce.framework.name</name>
             <value>yarn</value>
         </property>
         ```

   7. ä¿®æ”¹ `yarn-site.xml`

       å‘½ä»¤ï¼š

       ```shell
       vim yarn-site.xml
       ```

       æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š(ä¸€å®šè¦åœ¨ `<configuration> </configuration>` ä¹‹é—´æ·»åŠ )

       ```xml
       <property>
           <name>yarn.resourcemanager.hostname</name>
           <value>master</value>
       </property>

       <property>
           <name>yarn.nodemanager.aux-services</name>
           <value>mapreduce_shuffle</value>
       </property>
       ```

6. æŠŠ `hadoop` æ‹·åˆ°å…¶ä»–æœºå™¨ä¸Š(è¯·**é€æ¡åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œ**)

    ```shell
    scp -r /opt/hadoop slave1:/opt/
    scp -r /opt/hadoop slave2:/opt/
    ```

7. åœ¨ master ä¸Šåˆå§‹åŒ– `hadoop` é›†ç¾¤

    ```shell
    hadoop namenode -format
    ```

8. å¯åŠ¨èŠ‚ç‚¹

   - è¿›å…¥ `hadoop` çš„ `sbin` æ–‡ä»¶å¤¹

     ```shell
     cd /opt/hadoop/sbin
     ```

   - å¯åŠ¨ `hadoop`

     ```shell
     ./start-all.sh
     ```

9. ä½¿ç”¨ `jps` å‘½ä»¤æŸ¥çœ‹è¿›ç¨‹å¯åŠ¨æƒ…å†µ

   ```shell
   jps
   ```

   è‹¥ `master` æ˜¾ç¤º 

   ```shell
   Namenode
   Resourcemanager
   SecondaryNameNode
   Jps
   ```

   `slave1`ã€`slave2`æ˜¾ç¤ºï¼š

   ```shell
   Datanode
   Nodemanager
   Jps
   ```

   åˆ™å®‰è£…æˆåŠŸï¼Œå¦åˆ™å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°æ­¥éª¤æˆ–è€…é…ç½®æ–‡ä»¶æ˜¯å¦å‡ºé”™

10. `hadoop` é…ç½®çš„ç–‘éš¾è§£ç­”

    - `namenode` æ²¡æœ‰å¯åŠ¨æˆåŠŸï¼š

      æŸ¥çœ‹`namenode`çš„æ—¥å¿—ã€‚æ ¹æ®å®é™…æƒ…å†µéšæœºåº”å˜ã€‚

      å¤§éƒ¨åˆ†æƒ…å†µå°è¯•åˆ é™¤ `hadoop`çš„ `tmp` ç›®å½•ï¼Œè§£å†³`namenode` å¯åŠ¨æ•…éšœã€‚

    - ä»èŠ‚ç‚¹çš„ `NodeManage`r æ²¡æœ‰å¯åŠ¨

      å°è¯•å°† `hadoop` çš„é…ç½®æ–‡ä»¶æ‹·å‡ºï¼Œé‡æ–°è§£å‹å®‰è£… `hadoop` é‡æ–°åˆå§‹åŒ–ã€‚

    **æ³¨æ„ `hadoop` æ‹·è´åˆ°å…¶ä»–ä»èŠ‚ç‚¹åœ¨åˆå§‹åŒ– `namenode` ä¹‹å‰ã€‚**

11. å®‰è£…æˆåŠŸåå¯ä»¥æ‰“å¼€æµè§ˆå™¨ï¼Œè¾“å…¥ç½‘å€ `master` çš„ `IP` + `:50070`(æ³¨æ„æ˜¯è‹±æ–‡çš„ `:`)

     example

     ```
     192.168.100.144:50070
     ```

     ![image-20201126122310172](image/image-20201126122310172.png)

#### 8ã€MySQL

1. å› ä¸º `CentOS 7` é»˜è®¤å®‰è£…äº† `mariadb-libs` ä¼šå¯¼è‡´å®‰è£…ä¸ä¸Š `MySQL` æ‰€ä»¥å…ˆå¸è½½å†²çªæº

    ```shell
    rpm -e --nodeps mariadb-libs
    ```
    
2. ä½¿ç”¨ `rpm` åŒ…å®‰è£…(å…ˆå®‰è£… `MySQL-client` å†å®‰è£… `MySQL-server`ï¼Œä¸€æ¡æ¡æ‰§è¡Œ)

    ```shell
    rpm -ivh MySQL-client-5.1.73-1.glibc23.x86_64.rpm
    rpm -ivh MySQL-server-5.1.73-1.glibc23.x86_64.rpm
    ```

3. å¯åŠ¨ `mysql` æœåŠ¡(å®‰è£…å¥½ `server` åä¸€èˆ¬ä¼šè‡ªå¯åŠ¨ï¼Œä¸éœ€è¦æ‰‹åŠ¨å¯åŠ¨ï¼Œå¯ä»¥çœç•¥)

    ```shell
    service mysql start
    ```

4. åŠ å…¥åˆ°å¼€æœºå¯åŠ¨é¡¹

    ```shell
    chkconfig mysql on
    ```

5. åˆå§‹åŒ–é…ç½® `mysql` æœåŠ¡

    ```shell
    mysql_secure_installation
    ```

    - `Enter current password for root (enter for none):` ï¼šç›´æ¥æŒ‰å›è½¦

    - `Set root password? [Y/n]`ï¼šè¾“å…¥ `Y`
    - `New password:`ï¼š è¾“å…¥ `123456`
    - `Re-enter new password:`ï¼šå†è¾“å…¥ `123456`
    - åé¢å…¨éƒ¨å›è½¦å³å¯

6. ç™»å½• MySQL(å¯†ç æ˜¯ï¼š`123456`)

    ```shell
    mysql -uroot -p
    ```

7. è®¾ç½®ç”¨æˆ·æƒé™(è¯·**é€æ¡åœ¨ SQL å‘½ä»¤è¡Œä¸­è¿è¡Œ**)

    ```sql
    use mysql;
    update user set host='%' where user = 'root';
    -- æ³¨æ„ä¸Šé¢ä¸€è¡Œæ‰§è¡Œå®Œä¹‹åå¿…å®šä¼šæŠ¥é”™ï¼Œå¦‚ ERROR 1062 (23000): Duplicate entry '%-root' for key 'PRIMARY'
    -- ç›´æ¥æ— è§†æ‰§è¡Œä¸‹ä¸€å¥
    flush privileges;
    ```

9. å»º `hive` è¡¨

   ```sql
   create database hive default charset utf8;
   ```

10. æ£€æŸ¥è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ

    ```sql
    show databases;
    ```

11. é€€å‡º `MySQL`

    ```sql
    exit;
    ```

12. `MySQL` é…ç½®çš„ç–‘éš¾è§£ç­”

- æ£€æŸ¥ `service mysql status`ï¼Œå¦‚æœåœ¨éå¯åŠ¨çŠ¶æ€æœ‰é”ä½ï¼Œç›´æ¥åˆ å»é”æ–‡ä»¶ï¼ˆ`status` ä¸Šä¼šæŒ‡å®šè·¯å¾„ï¼‰ã€‚

- `mysql` å¯èƒ½ä¼šå‡ºç°å¯åŠ¨ä¸å®Œå…¨çš„æƒ…å†µã€‚`ps -aux | ps -ef` æ£€æŸ¥æ‰€æœ‰ `mysql` æœåŠ¡çš„è¿›ç¨‹å·ï¼Œ`kill -9` æ€æ­» `mysql` çš„æ‰€æœ‰è¿›ç¨‹é‡æ–°å¯åŠ¨ã€‚

#### 9ã€hive é…ç½®æ–‡ä»¶

1. è§£å‹ `hive` å®‰è£…åŒ…

   ```shell
   tar -zxvf apache-hive-2.2.0-bin.tar.gz
   ```

2. å°†è§£å‹å‡ºæ¥çš„æ–‡ä»¶å¤¹ ` hadoop-2.7.6.` ç§»åŠ¨åˆ° `/opt` ç›®å½•ä¸‹ï¼Œå¹¶ä¿®æ”¹æ–‡ä»¶å¤¹åç§°ä¸º `hive`

   ```shell
   mv apache-hive-2.2.0-bin /opt/hive
   ```

3. é…ç½® `hive` çš„ç¯å¢ƒå˜é‡

   å‘½ä»¤ï¼š

   ```shell
   vim /etc/profile
   ```

   åœ¨ `hadoop` ç¯å¢ƒå˜é‡åæ·»åŠ ä»¥ä¸‹å†…å®¹

   ```shell
   export HIVE_HOME=/opt/hive
   export PATH=$HIVE_HOME/bin:$PATH
   ```

   ä½¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ

   ```shell
   source /etc/profile
   ```

4. ä¿®æ”¹ `hive` çš„é…ç½®æ–‡ä»¶

   1. è¿›å…¥ `hive` é…ç½®æ–‡ä»¶ç›®å½•

      ```shell
      cd /opt/hive/conf
      ```

   2. ä¿®æ”¹ `hive-env.sh`

      - ä»æ¨¡æ¿ä¸­æ‹·è´`hive-env.sh`

        ```shell
        cp hive-env.sh.template hive-env.sh
        ```

      - ç¼–è¾‘ `hive-env.sh`

        ```shell
        vim hive-env.sh
        ```

        æ·»åŠ ä»¥ä¸‹å†…å®¹

        ```shell
        HADOOP_HOME=/opt/hadoop
        JAVA_HOME=/opt/jdk
        HIVE_HOME=/opt/hive
        ```

        ![image-20201126115511637](image/image-20201126115511637.png)

   3. ä¿®æ”¹ `hive-site.xml`

      - ä»æ¨¡æ¿ä¸­æ‹·è´`hive-site.xml`(æ³¨æ„æ–‡ä»¶åç§°ä¸åŒ)

        ```shell
        cp hive-default.xml.template hive-site.xml
        ```

      - é…ç½® `vim` (å¯é€‰)

        ä¸ºäº†æ–¹ä¾¿æŸ¥æ‰¾éœ€è¦ä¿®æ”¹çš„å†…å®¹å¯ä»¥è¿›è¡Œä¸€äº› `vim` çš„é…ç½®

        å‘½ä»¤ï¼š

        ```shell
        vim ~/.vimrc
        ```

        æ·»åŠ ä»¥ä¸‹å†…å®¹

        ```shell
        set ignorecase " è‡ªåŠ¨è·³åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç»“æœ
        set incsearch  " æœç´¢æ—¶å¿½ç•¥å¤§å°å†™
        ```

      - ä¿®æ”¹  `hive-site.xml` å†…å®¹

        å‘½ä»¤ï¼š

        ```shell
        vim hive-site.xml
        ```

        æŒ‰ `/` æœç´¢ ä»¥ä¸‹ `<name></name>` å†…çš„å†…å®¹ï¼Œä¿®æ”¹å¯¹åº” `<value></value>` å†…çš„å†…å®¹

        ä¿®æ”¹ä¸€æ¡åæŒ‰ `Esc` **é€€å‡ºç¼–è¾‘æ¨¡å¼**è¿›è¡Œä¸‹ä¸€æ¬¡æœç´¢ï¼ï¼ï¼

        ```xml
        <property>
           <name>javax.jdo.option.ConnectionURL</name> 
           <value>jdbc:mysql://è™šæ‹Ÿæœºip(ä¸è¦ä½¿ç”¨hosts):3306/hive?useSSL=false</value> 
        </property>
        
        <property> 
           <name>javax.jdo.option.ConnectionDriverName </name> 
           <value>com.mysql.jdbc.Driver </value> 
        </property> 
        
        <property>
           <name>javax.jdo.option.ConnectionUserName</name>
           <value>root</value>
        </property> 
        
        <property> 
           <name>javax.jdo.option.ConnectionPassword </name> 
           <value>123456</value> 
        </property>
        
        <property>
           <name>hive.querylog.location</name>
        <value>/opt/hive/tmp</value>
        </property>
        
        <property>
           <name>hive.exec.local.scratchdir</name>
        <value>/opt/hive/tmp</value>
        </property>
        
        <property>
            <name>hive.downloaded.resources.dir</name>
            <value>/opt/hive/tmp</value>
        </property>
        ```

        example:

        ![image-20201126120542284](image/image-20201126120542284.png)

5. å°† `MySQL` é©±åŠ¨ `jar` åŒ…æ‹·è´åˆ° `hive `(è¿™é‡Œä½¿ç”¨çš„æ˜¯ `5.1.17` ç‰ˆæœ¬)

   ```shell
   cp /root/mysql-connector-java-5.1.17-bin.jar /opt/hive/lib/
   ```

6. æ›¿æ¢æ‰ `hadoop` çš„ `jline` çš„ç‰ˆæœ¬ï¼Œä½¿ç”¨ `hive` çš„ `2,12` ç‰ˆæœ¬

   ```shell
   cp /opt/hive/lib/jline-2.12.jar /opt/hadoop/share/hadoop/yarn/lib/
   ```

   **æ³¨æ„ï¼š** å¦‚æœå®‰è£…çš„æ˜¯ `hadoop1.6` ç‰ˆæœ¬ï¼Œåˆ™éœ€è¦å…ˆåˆ é™¤è‡ªå¸¦çš„ `0.9.94` ç‰ˆæœ¬çš„ `jline`

   ```shell
   rm -rf /opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar
   ```

7. æ‹·è´é…ç½®æ–‡ä»¶åˆ°å¦å¤–ä¸¤å°è™šæ‹Ÿæœº

   ```shell
   scp -r /opt/hive slave1:/opt
   scp -r /opt/hive slave2:/opt
   ```

8. åœ¨ `master` ä¸Šåˆå§‹åŒ–å…ƒæ•°æ®

   ```shell
   schematool -dbType mysql -initSchema
   ```

9. å¯åŠ¨ `hive`

   ```
   hive
   ```

   è‹¥å‡ºç°ä»¥ä¸‹å†…å®¹ `hive` å¯åŠ¨æˆåŠŸï¼Œå¦åˆ™å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸Šæ­¥éª¤æ˜¯å¦å‡ºé”™

   ```hive
   hive>
   ```

10. `hive` çš„åŸºæœ¬æ“ä½œ

    æŸ¥çœ‹æ•°æ®åº“

    ```sql
    show databases;
    ```

    æ˜¾ç¤ºä½¿ç”¨çš„æ•°æ®åº“åç§°

    ```sql
    set hive.cli.print.current.db=true;
    ```

    é€€å‡º

    ```sql
    exit;
    ```

11. `hadoop` é€€å‡º `safe mode`(å¯ä»¥ä¸åšè¿™ä¸€æ­¥)

    ```shell
    hadoop dfsadmin -safemode leave
    ```

12. `hdfs-site.xml` çš„ä¸€äº›é…ç½®è¯¦æƒ…(äº†è§£)

    ```shell
    truedfs.permissions					è®¾ç½®dfsæƒé™æ‰“å¼€
    dfs.replication						è®¾ç½®HDFSæ•°æ®å—çš„å¤‡ä»½æ•°
    dfs.client.block.write.retries		è®¾ç½®æ•°æ®å—å†™å…¥çš„æœ€å¤šé‡è¯•æ¬¡æ•°
    dfs.max.objects						è®¾ç½®dfsæœ€å¤§å¹¶å‘å¯¹è±¡æ•°
    dfs.datanode.handler.count			è®¾ç½®DateNodeå¯åŠ¨çš„æœåŠ¡çº¿ç¨‹æ•°
    ```

13. `hdfs dfs` çš„ä¸€äº›æŒ‡ä»¤(å®è·Ÿ bash çš„æŒ‡ä»¤å·®ä¸å¤šï¼ŒæŒæ¡)

    ```shell
    hdfs dfs -ls							(æ˜¾ç¤º hdfs æŒ‡å®šè·¯å¾„ä¸‹çš„æ–‡ä»¶)
    hdfs dfs -mkdir [-p]					(åœ¨ hdfs ä¸Šåˆ›å»ºæ–‡ä»¶å¤¹)
    hdfs dfs -touchz  						(åœ¨ hdfs ä¸Šåˆ›å»ºæ–‡ä»¶ï¼Œä¸ bash çš„ touch ç›¸åŒ)
    hdfs dfs -rm -r							(åˆ é™¤ hdfs ä¸Šçš„æ–‡ä»¶)
    hdfs dfs -appendToFile File1 File2   	(è¿½åŠ  File1 åˆ° File2 å°¾éƒ¨)
    hdfs dfs -chmod 644 File1				(ä¿®æ”¹ hdfs ä¸ŠæŒ‡å®šæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„æƒé™)
    hdfs dfs -cat							(æ˜¾ç¤º hdfs ä¸ŠæŒ‡å®šæ–‡ä»¶çš„å†…å®¹)
    hdfs dfs -put							(ä¸Šä¼ æ–‡ä»¶åˆ° hdfs ä¸Š)
    
    # ä¸Šä¼ å‘½ä»¤ï¼šhdfs dfs -put æœ¬åœ°æ–‡ä»¶è·¯å¾„ hdfsè·¯å¾„
    hdfs dfs -put /usr/local/testdata/anhui.txt /data/
    
    # ä¸‹è½½å‘½ä»¤ï¼šä¸Šä¼ å‘½ä»¤ï¼šhdfs dfs -get  hdfsè·¯å¾„ æœ¬åœ°æ–‡ä»¶è·¯å¾„
    hdfs dfs -get /data/anhui.txt /usr/local/
    ```

14. `hdfs` ä¸€äº›é—®é¢˜è§£å†³

    - ç¬¬ä¸€æ­¥æ£€æŸ¥è™šæ‹Ÿæœºé˜²ç«å¢™æ˜¯å¦å…³é—­

      HDFS ä¼ è¾“é—®é¢˜ä¼˜å…ˆè€ƒè™‘é˜²ç«å¢™çš„é—®é¢˜ï¼Œä¼˜å…ˆå…ˆå°è¯•å…³é—­é˜²ç«å¢™ï¼ˆä½†å®é™…æ¯”èµ›ç¯å¢ƒå¥½åƒæ²¡æœ‰é˜²ç«å¢™ï¼‰

    - æŠ¥é”™ `appendToFile: Failed to APPEND_FILE /data/file/data1.csv for DFSClient_NONMAPREDUCE_-1657827142_1 on 192.168.1.100 because lease recovery is in progress. Try again later.`

      åœ¨ `hdfs-site.xml` ä¸­è¿½åŠ  `name: dfs.client.block.write.replace-datanode-on-failure.policy value=NEVER`

#### 10ã€zookeeper(äº†è§£ï¼Œä¸éœ€è¦å®‰è£…)

1. è§£å‹ã€ç§»åŠ¨åˆ° `/opt` ä¸‹

   åŒ `hadoop` ç•¥

2. é…ç½®ç¯å¢ƒå˜é‡(é…ç½®å¥½è®°å¾— `source /etc/profile`)

   ```shell
   ZOOKEEPER_HOME=/opt/zookeeper
   export PATH=$ZOOKEEPER_HOME/bin:$PATH
   ```

2. ä¿®æ”¹é…ç½®æ–‡ä»¶(é…ç½®æ–‡ä»¶åœ¨ `/opt/zookeeper/conf/` ç›®å½•ä¸‹)

   - `zoo.cfg`ï¼ˆä» `zoo_sample.cfg` å¤åˆ¶ï¼‰

     ```
     dataDir=/opt/zookeeper/data
     server.0=master:2888:3888
     server.1=slave1:2888:3888
     server.2=slave2:2888:3888
     ```

3. åŒæ­¥åˆ°å…¶å®ƒèŠ‚ç‚¹

   ```shell
   scp -r /opt/zookeeper slave1:/opt
   scp -r /opt/zookeeper slave2:/opt
   ```

4. åˆ›å»º `/opt/zookeepe/data` ç›®å½•(ä¸‰æœºå™¨éƒ½éœ€è¦é…ç½®)

   ```
   mkdir /opt/zookeeper/data
   ```

   åˆ†åˆ«åœ¨æ¯å°è™šæ‹Ÿæœºä¸‹æ“ä½œï¼š

   1. åœ¨ `data` ç›®å½•ä¸‹åˆ›å»º `myid` æ–‡ä»¶

   2. ä¸‰å°è™šæ‹Ÿæœºåˆ†åˆ«åœ¨ `myid` æ–‡ä»¶å†…å¡«å…¥ `0, 1, 2` (æ ¹æ® `zoo.cfg` ä¸­ä¸€ä¸€å¯¹åº”)

      ```shell
      master å¡«å…¥ 0
      slave1 å¡«å…¥ 1
      slave2 å¡«å…¥ 2
      ```

5. å¯åŠ¨ `zookeeper` (ä¸‰å°è™šæ‹Ÿæœºéƒ½è¦æ“ä½œ)

   ```shell
   zkServer.sh start
   ```

6. `zookeeper` ä¸€äº›å…¶ä»–çš„æŒ‡ä»¤

   æŸ¥çœ‹çŠ¶æ€

   ```shell
   zkServer.sh status
   ```

   å½“æœ‰ä¸€ä¸ª `leader` çš„æ—¶å€™å¯åŠ¨æˆåŠŸï¼Œè¿æ¥ `zookeeper`

   ```shell
   zkCli.sh
   ```

   `zk shel` æ“ä½œ

   ```shell
   ls /                  æŸ¥æ‰¾æ ¹ç›®å½•
   create /test abc      åˆ›å»ºèŠ‚ç‚¹å¹¶èµ‹å€¼
   get /test             è·å–æŒ‡å®šèŠ‚ç‚¹çš„å€¼
   set /test cb          è®¾ç½®å·²å­˜åœ¨èŠ‚ç‚¹çš„å€¼
   rmr /test             é€’å½’åˆ é™¤èŠ‚ç‚¹
   delete /test/test01   åˆ é™¤ä¸å­˜åœ¨å­èŠ‚ç‚¹çš„èŠ‚ç‚¹
   ```

#### 11ã€`hbase` é…ç½®æ–‡ä»¶

1. è§£å‹ã€ç§»åŠ¨åˆ° `/opt` ä¸‹

   åŒ `hadoop` ç•¥

2. é…ç½®ç¯å¢ƒå˜é‡ (é…ç½®å¥½è®°å¾— `source /etc/profile`)

   ```shell
   export HBASE_HOME=/opt/hbase
   export PATH=$HBASE_HOME/bin:$PATH
   ```

3. ä¿®æ”¹é…ç½®æ–‡ä»¶(é…ç½®æ–‡ä»¶åœ¨ `/opt/hbase/conf/` ç›®å½•ä¸‹)
   1. ä¿®æ”¹ `hbase-env.sh`

      æ·»åŠ ä»¥ä¸‹å†…å®¹

      ```shell
      export JAVA_HOME=/opt/jdk
      export HBASE_MANAGES_ZK=true
      ```

      ![image-20201126130809697](image/image-20201126130809697.png)

   2. ä¿®æ”¹ `hbase-site.xml` (åœ¨ `<configuration></configuration>` ä¹‹é—´åŠ å…¥ä»¥ä¸‹å†…å®¹)

      ```xml
      <property> 
      	<name>hbase.rootdir</name>
          <value>hdfs://matser:9000/hbase</value>
      </property>
      
      <property> 
          <name>hbase.cluster.distributed</name>
          <value>true</value> 
      </property> 
      
      <property> 
          <name>hbase.zookeeper.quorum</name>
          <value>master,slave1,slave2</value>
      </property>
      
      <property>
         <name>hbase.zookeeper.property.dataDir</name> 
         <value>/opt/hbase/zookeeper</value>
      </property>
      ```

      ![image-20201126130952410](image/image-20201126130952410.png)

4. ä¿®æ”¹ `regionservers` åˆ é™¤ `localhost` æ·»åŠ ä»¥ä¸‹å†…å®¹

   ```shell
   slave1
   slave2
   ```

5. æ‹·è´é…ç½®æ–‡ä»¶åˆ°æ‰€æœ‰æœºå™¨ä¸Š

   ```shell
   scp -r /opt/hbase slave1:/opt
   scp -r /opt/hbase slave2:/opt
   ```

6. å¯åŠ¨ `hbase`

   ```shell
   start-hbase.sh
   ```

7. è¿›å…¥ `hbase sell`

   ```shell
   hbase shell
   ```

   åœ¨`master`ã€`slave1`ã€`slave2 `ä¸­çš„ä»»æ„ä¸€å°æœºå™¨è¿›å…¥ `hbase` è‡ªå¸¦çš„`shell`ç¯å¢ƒï¼Œç„¶åä½¿ç”¨å‘½ä»¤ `version` ç­‰ï¼Œè¿›è¡ŒæŸ¥çœ‹ `hbase` ä¿¡æ¯åŠå»ºç«‹è¡¨ç­‰æ“ä½œ

8. `jps` æŸ¥çœ‹è¿›ç¨‹

   master

   ```
   HMaster
   HQuorumPeer
   ```

   slave

   ```
   HRegionServer
   HQuorumPeer
   ```

#### 12ã€Spark

1. è§£å‹ã€ç§»åŠ¨åˆ° `/opt` ä¸‹

   åŒ `hadoop` ç•¥

2. é…ç½®ç¯å¢ƒå˜é‡ (é…ç½®å¥½è®°å¾— `source /etc/profile`)

   ```shell
   export SPARK_HOME=/opt/spark
   export PATH=$SPARK_HOME/bin:$PATH
   ```

3. ä¿®æ”¹é…ç½®æ–‡ä»¶(é…ç½®æ–‡ä»¶åœ¨ `/opt/spark/conf/` ç›®å½•ä¸‹)

4. `spark-env.sh`(ä» `spark-env.sh.template` å¤åˆ¶ï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹)

   **æ³¨æ„ï¼š`SPARK_WORKER_CORES` å’Œ `SPARK_WORKER_MEMORY` è¯·æ ¹æ®è™šæ‹Ÿæœºæƒ…å†µè®¾ç½®**

   ```shell
   export SPARK_MASTER_IP=master
   export SPARK_MASTER_PORT=7077
   export SPARK_WORKER_CORES=1
   export SPARK_WORKER_INSTANCES=1
   export SPARK_WORKER_MEMORY=1g
   export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
   export JAVA_HOME=/opt/jdk
   ```

5. `slaves`(ä» `slaves.template` å¤åˆ¶ï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹ï¼Œä¸ç”¨åˆ é™¤ `localhosts`)

   ```
   slave1
   slave2
   ```

6. æ‹·è´é…ç½®æ–‡ä»¶åˆ°æ‰€æœ‰æœºå™¨ä¸Š

   ```shell
   scp -r /opt/spark slave1:/opt
   scp -r /opt/spark slave2:/opt
   ```

7. å¯åŠ¨ `Spark`

   ```shell
   cd /opt/spark/sbin
   ./start-all.sh
   ```

8. `jps`æŸ¥çœ‹è¿›ç¨‹

   `master`

   ```
   Master
   Worker
   ```

   `slave`

   ```
   Worker
   ```

9. è®¿é—® `Spark UI`

   åŒ `hadoop`ï¼Œ`ip` åœ°å€ä¸º `master` çš„ `ip` åœ°å€

   ```
   http://192.168.100.144:8080
   ```

   ![image-20201126133128252](image/image-20201126133128252.png)

10. å¾€ yarn æäº¤ä»»åŠ¡éœ€è¦å¢åŠ ä¸¤ä¸ªé…ç½®(`/opt/hadoop/etc/hadoop/yarn-site.xml`)

   ```xml
   <property>
       <name>yarn.nodemanager.pmem-check-enabled</name>
       <value>false</value>
   </property>
   
   <property>
       <name>yarn.nodemanager.vmem-check-enabled</name>
       <value>false</value>
   </property>
   ```

   åŒæ­¥åˆ°å…¶ä»–èŠ‚ç‚¹

   ```shell
   scp -r /opt/hadoop/etc/hadoop/yarn-site.xml slave1:/opt/hadoop/etc/hadoop/
   scp -r /opt/hadoop/etc/hadoop/yarn-site.xml slave2:/opt/hadoop/etc/hadoop/
   ```

   é‡å¯ `yarn`

   ```shell
   ./opt/hadoop/sbin/stop-yarn.sh
   ./opt/hadoop/sbin/start-yarn.sh
   ```

#### 13ã€Python

**æ³¨æ„ï¼š** ä»¥ä¸‹ `Python 3` çš„å®‰è£…ä¾èµ–äº `tensorflow_torch.tgz` å†…çš„æ–‡ä»¶ï¼Œè¯·å›åˆ°æœ€ä¸Šæ–¹ç‚¹å‡»é“¾æ¥è¿›è¡Œä¸‹è½½

1. å®‰è£…ç¼–è¯‘æ‰€éœ€çš„ç¯å¢ƒ

   é€æ¡åœ¨å‘½ä»¤è¡Œæ‰§è¡Œ

   ```shell
   tar -zxvf tensorflow_torch.tgz
   cd tensorflow_torch/rpm
   rpm -ivh --nodeps --force *.rpm
   ```

2. ç¼–è¯‘ `Python` ï¼Œå®‰è£…

   è§£å‹

   ```shell
   tar -zxvf Python-3.6.3.tgz
   ```

   è¿›å…¥ `Python-3.6.3` æ–‡ä»¶å¤¹

   ```shell
   cd Python-3.6.3
   ```

   ç¼–è¯‘å®‰è£…(é€æ¡åœ¨å‘½ä»¤è¡Œæ‰§è¡Œ)

   ```shell
   ./configure --prefix=/opt/python36
   make
   make install
   ```

3. åˆ›å»ºè½¯é“¾æ¥

   ```
   ln -s /opt/python36/bin/python3 /usr/bin/python3
   ln -s /opt/python36/bin/pip3 /usr/bin/pip3
   ```

4. å‡çº§ pip

   ```shell
   cd /root/tensorflow_torch
   pip3 install pip-20.2.3-py2.py3-none-any.whl
   ```

   

5. å®‰è£… `Tensorflow`(é€æ¡æ‰§è¡Œæœ€åä¸¤è¡Œ)

   ```shell
   # numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl
   # protobuf-3.9.2-cp36-cp36m-manylinux1_x86_64.whl
   # requirements.txt
   # six-1.12.0-py2.py3-none-any.whl
   # tensorflow-1.1.0rc1-cp36-cp36m-manylinux1_x86_64.whl
   # Werkzeug-0.16.0-py2.py3-none-any.whl
   # wheel-0.33.6-py2.py3-none-any.whl
   cd /root/tensorflow_torch/tensorflow
   pip3 install *.whl
   ```

   `Tensorflow` æµ‹è¯•ä»£ç (`Python3` ç¯å¢ƒä¸‹è¿è¡Œ)

   ```python
   import tensorflow as tf
   sess = tf.Session()
   hello = tf.constant('Hello,world!')
   print(sess.run(hello))
   ```

6. å®‰è£… `PyTorch`

   ```shell
   cd /root/tensorflow_torch/pytorch
   # å®‰è£… future(è¦éœ€è¦å…ˆå®‰è£…ï¼Œä¸ç„¶åé¢ä¼šæŠ¥é”™)
   tar zxvf future-0.18.2.tar.gz
   cd future-0.18.2
   python3 setup.py install
   
   # å®‰è£…å…¶ä»–
   # Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl
   # torch-1.6.0+cpu-cp36-cp36m-linux_x86_64.whl
   # torchvision-0.7.0+cpu-cp36-cp36m-linux_x86_64.whl
   cd ..
   pip3 install *.whl
   ```

   `PyTorch` æµ‹è¯•ä»£ç 

   ```python
   import torch
   print(torch.__version__)
   print(torch.tensor([1, 2]))
   ```

7. æ’é”™

   - `python3.6: error while loading shared libraries: libpython3.6m.so.1.0:cannot open shared object file: No such file or directory`

     ä½¿ç”¨å‘½ä»¤ `ldd /usr/local/Python-3.6/bin/python3` æ£€æŸ¥å…¶åŠ¨æ€é“¾æ¥

     æ‹·è´æ–‡ä»¶åˆ° `lib` åº“

     ```shell
     cd /root/Python-3.6.5
     cp libpython3.6m.so.1.0 /usr/local/lib64/
     cp libpython3.6m.so.1.0 /usr/lib/
     cp libpython3.6m.so.1.0 /usr/lib64/
     ```

8. æœ‰ç½‘ç»œæƒ…å†µä¸‹çš„å®‰è£…(æ‰§è¡Œå®Œç¬¬äºŒæ¡å‘½ä»¤åï¼Œè¯·çœ‹ç¬¬ 9 æ­¥)

   ```shell
   yum install python3
   pip3 install --upgrade pip
   pip3 install tensorflow
   pip3 install torch
   ```

9. ä¿®æ”¹ pip æº

   `pip` é»˜è®¤æºä¸‹è½½å¾ˆæ…¢æ‰€ä»¥å»ºè®®ä¿®æ”¹æˆå›½å†…é•œåƒæº(**ä»¥ä¸‹æ–¹æ³•ä»»é€‰å…¶ä¸€**)

   1. æ‰‹åŠ¨ä¿®æ”¹

      - åœ¨ `~/`ç›®å½•ä¸‹æ–°å»º `.pip`æ–‡ä»¶å¤¹: 

        ```shell
        mkdir ~/.pip
        ```

      - åœ¨ `~/.pip`æ–‡ä»¶å¤¹ä¸‹æ–°å»º `pip.conf`å†™å…¥ä»¥ä¸‹å†…å®¹ï¼š`vim ~/.pip/pip.conf`

        ```conf
        [global]
        index-url = http://pypi.douban.com/simple/
        [install]
        trusted-host = pypi.douban.com
        ```

   2. ä½¿ç”¨ `pqi` ä¿®æ”¹

      ```shell
      pip3 install pqi
      pqi ls
      pqi use <name> # <name> ä¸ºä»¥ä¸Šæ˜¾ç¤ºæºçš„åç§°ï¼Œå»ºè®®ä½¿ç”¨ ustc æˆ– douban
      ```

      ![image-20201126134417164](image/image-20201126134417164.png)

      ![image-20201126134440165](image/image-20201126134440165.png)

      ![image-20201126134458391](image/image-20201126134458391.png)